{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4479c9c",
   "metadata": {},
   "source": [
    "# Finetuning Embeddings For Domain Specific Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0db934",
   "metadata": {},
   "source": [
    "## Imports and Class Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64653db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.12.13 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (3.12.13)\n",
      "Requirement already satisfied: aiosignal==1.4.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: aiosqlite==0.21.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.21.0)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.9.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: async-timeout==5.0.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: attrs==25.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (25.3.0)\n",
      "Requirement already satisfied: azure-core==1.35.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (1.35.0)\n",
      "Requirement already satisfied: azure-identity==1.23.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (1.23.0)\n",
      "Requirement already satisfied: banks==2.1.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.1.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.4 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (4.13.4)\n",
      "Requirement already satisfied: certifi==2025.6.15 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (2025.6.15)\n",
      "Requirement already satisfied: cffi==1.17.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.4.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (3.4.2)\n",
      "Requirement already satisfied: click==8.2.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (8.2.1)\n",
      "Requirement already satisfied: cohere==5.15.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (5.15.0)\n",
      "Requirement already satisfied: colorama==0.4.6 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 18)) (0.4.6)\n",
      "Requirement already satisfied: cryptography==45.0.5 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (45.0.5)\n",
      "Requirement already satisfied: dataclasses-json==0.6.7 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 20)) (0.6.7)\n",
      "Requirement already satisfied: datasets==3.6.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 21)) (3.6.0)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 22)) (0.7.1)\n",
      "Requirement already satisfied: Deprecated==1.2.18 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 23)) (1.2.18)\n",
      "Requirement already satisfied: dill==0.3.8 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 24)) (0.3.8)\n",
      "Requirement already satisfied: dirtyjson==1.0.8 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 25)) (1.0.8)\n",
      "Requirement already satisfied: distro==1.9.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 26)) (1.9.0)\n",
      "Requirement already satisfied: eval_type_backport==0.2.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 27)) (0.2.2)\n",
      "Requirement already satisfied: exceptiongroup==1.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 28)) (1.3.0)\n",
      "Requirement already satisfied: fastavro==1.11.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 29)) (1.11.1)\n",
      "Requirement already satisfied: filelock==3.18.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 30)) (3.18.0)\n",
      "Requirement already satisfied: filetype==1.2.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 31)) (1.2.0)\n",
      "Requirement already satisfied: frozenlist==1.7.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 32)) (1.7.0)\n",
      "Requirement already satisfied: fsspec==2025.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 33)) (2025.3.0)\n",
      "Requirement already satisfied: greenlet==3.2.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 34)) (3.2.3)\n",
      "Requirement already satisfied: griffe==1.7.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 35)) (1.7.3)\n",
      "Requirement already satisfied: h11==0.16.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 36)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 37)) (1.0.9)\n",
      "Requirement already satisfied: httpx==0.28.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 38)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 39)) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub==0.33.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 40)) (0.33.2)\n",
      "Requirement already satisfied: idna==3.10 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 41)) (3.10)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 42)) (3.1.6)\n",
      "Requirement already satisfied: jiter==0.10.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 43)) (0.10.0)\n",
      "Requirement already satisfied: joblib==1.5.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 44)) (1.5.1)\n",
      "Requirement already satisfied: llama-cloud==0.1.30 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 45)) (0.1.30)\n",
      "Requirement already satisfied: llama-cloud-services==0.6.41 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 46)) (0.6.41)\n",
      "Requirement already satisfied: llama-index==0.12.47 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 47)) (0.12.47)\n",
      "Requirement already satisfied: llama-index-agent-openai==0.4.12 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 48)) (0.4.12)\n",
      "Requirement already satisfied: llama-index-cli==0.4.4 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 49)) (0.4.4)\n",
      "Requirement already satisfied: llama-index-core==0.12.47 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 50)) (0.12.47)\n",
      "Requirement already satisfied: llama-index-embeddings-adapter==0.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 51)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-embeddings-openai==0.3.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 52)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-finetuning==0.3.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 53)) (0.3.2)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud==0.7.9 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 54)) (0.7.9)\n",
      "Requirement already satisfied: llama-index-instrumentation==0.2.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 55)) (0.2.0)\n",
      "Requirement already satisfied: llama-index-llms-azure-openai==0.3.4 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 56)) (0.3.4)\n",
      "Requirement already satisfied: llama-index-llms-mistralai==0.4.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 57)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-llms-openai==0.4.7 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 58)) (0.4.7)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai==0.5.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 59)) (0.5.3)\n",
      "Requirement already satisfied: llama-index-postprocessor-cohere-rerank==0.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 60)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-program-openai==0.3.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 61)) (0.3.2)\n",
      "Requirement already satisfied: llama-index-question-gen-openai==0.3.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 62)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-readers-file==0.4.11 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 63)) (0.4.11)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse==0.4.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 64)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-workflows==1.0.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 65)) (1.0.1)\n",
      "Requirement already satisfied: llama-parse==0.6.41 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 66)) (0.6.41)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 67)) (3.0.2)\n",
      "Requirement already satisfied: marshmallow==3.26.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 68)) (3.26.1)\n",
      "Requirement already satisfied: mistralai==1.9.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 69)) (1.9.1)\n",
      "Requirement already satisfied: mpmath==1.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 70)) (1.3.0)\n",
      "Requirement already satisfied: msal==1.32.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 71)) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions==1.3.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 72)) (1.3.1)\n",
      "Requirement already satisfied: multidict==6.6.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 73)) (6.6.3)\n",
      "Requirement already satisfied: multiprocess==0.70.16 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 74)) (0.70.16)\n",
      "Requirement already satisfied: mypy_extensions==1.1.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 75)) (1.1.0)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 76)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 77)) (3.4.2)\n",
      "Requirement already satisfied: nltk==3.9.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 78)) (3.9.1)\n",
      "Requirement already satisfied: numpy==2.2.6 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 79)) (2.2.6)\n",
      "Requirement already satisfied: openai==1.93.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 80)) (1.93.1)\n",
      "Requirement already satisfied: packaging==25.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 81)) (25.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 82)) (2.2.3)\n",
      "Requirement already satisfied: pillow==11.3.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 83)) (11.3.0)\n",
      "Requirement already satisfied: platformdirs==4.3.8 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 84)) (4.3.8)\n",
      "Requirement already satisfied: propcache==0.3.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 85)) (0.3.2)\n",
      "Requirement already satisfied: pyarrow==20.0.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 86)) (20.0.0)\n",
      "Requirement already satisfied: pycparser==2.22 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 87)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.11.7 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 88)) (2.11.7)\n",
      "Requirement already satisfied: pydantic_core==2.33.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 89)) (2.33.2)\n",
      "Requirement already satisfied: PyJWT==2.10.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 90)) (2.10.1)\n",
      "Requirement already satisfied: pypdf==5.7.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 91)) (5.7.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 92)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.1.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 93)) (1.1.1)\n",
      "Requirement already satisfied: pytz==2025.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 94)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 95)) (6.0.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 96)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.4 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 97)) (2.32.4)\n",
      "Requirement already satisfied: safetensors==0.5.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 98)) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.7.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 99)) (1.7.0)\n",
      "Requirement already satisfied: scipy==1.15.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 100)) (1.15.3)\n",
      "Requirement already satisfied: sentence-transformers==5.0.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 101)) (5.0.0)\n",
      "Requirement already satisfied: six==1.17.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 102)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 103)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.7 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 104)) (2.7)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.41 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 105)) (2.0.41)\n",
      "Requirement already satisfied: striprtf==0.0.26 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 106)) (0.0.26)\n",
      "Requirement already satisfied: sympy==1.14.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 107)) (1.14.0)\n",
      "Requirement already satisfied: tenacity==9.1.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 108)) (9.1.2)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 109)) (3.6.0)\n",
      "Requirement already satisfied: tiktoken==0.9.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 110)) (0.9.0)\n",
      "Requirement already satisfied: tokenizers==0.21.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 111)) (0.21.2)\n",
      "Requirement already satisfied: torch==2.7.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 112)) (2.7.1)\n",
      "Requirement already satisfied: tqdm==4.67.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 113)) (4.67.1)\n",
      "Requirement already satisfied: transformers==4.53.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 114)) (4.53.1)\n",
      "Requirement already satisfied: types-requests==2.32.4.20250611 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 115)) (2.32.4.20250611)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 116)) (0.9.0)\n",
      "Requirement already satisfied: typing-inspection==0.4.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 117)) (0.4.1)\n",
      "Requirement already satisfied: typing_extensions==4.14.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 118)) (4.14.1)\n",
      "Requirement already satisfied: tzdata==2025.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 119)) (2025.2)\n",
      "Requirement already satisfied: urllib3==2.5.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 120)) (2.5.0)\n",
      "Requirement already satisfied: wrapt==1.17.2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 121)) (1.17.2)\n",
      "Requirement already satisfied: xxhash==3.5.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 122)) (3.5.0)\n",
      "Requirement already satisfied: yarl==1.20.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from -r requirements.txt (line 123)) (1.20.1)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from llama-index-core==0.12.47->-r requirements.txt (line 50)) (80.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\E\\EIL\\embeddings\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, SentenceTransformerModelCardData\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator, SequentialEvaluator\n",
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "from sentence_transformers import SentenceTransformerTrainingArguments, SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.util import cos_sim\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1cf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.llms import LLM, CompletionResponse\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.finetuning import generate_qa_embedding_pairs\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c0a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\E\\EIL\\embeddings\\.venv\\lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:628: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "class HuggingFacePhi3LLM(LLM):\n",
    "    tokenizer: any = None\n",
    "    model: any = None\n",
    "    generator: any = None\n",
    "\n",
    "    def __init__(self, model_name=\"microsoft/phi-3-mini-4k-instruct\", device=\"cuda\"):\n",
    "        object.__setattr__(self, 'tokenizer', AutoTokenizer.from_pretrained(model_name))\n",
    "        object.__setattr__(self, 'model', AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\"))\n",
    "        object.__setattr__(self, 'generator', pipeline(\"text-generation\", model=self.model, tokenizer=self.tokenizer))\n",
    "\n",
    "    def complete(self, prompt: str, **kwargs) -> CompletionResponse:\n",
    "        response = self.generator(prompt, max_new_tokens=128, do_sample=False)[0][\"generated_text\"]\n",
    "        # Strip prompt from response if model echoes it\n",
    "        answer = response.replace(prompt, \"\").strip()\n",
    "        return CompletionResponse(text=answer)\n",
    "\n",
    "    def achat(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def acomplete(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def astream_chat(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def astream_complete(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def chat(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def metadata(self):\n",
    "        return {}\n",
    "\n",
    "    def stream_chat(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def stream_complete(self, *args, **kwargs):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127fcc9",
   "metadata": {},
   "source": [
    "## Creation of DataSets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9c0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(files, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Loading files {files}\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(input_files=files)\n",
    "    docs = reader.load_data()\n",
    "    if verbose:\n",
    "        print(f\"Loaded {len(docs)} docs\")\n",
    "\n",
    "    parser = SentenceSplitter()\n",
    "    nodes = parser.get_nodes_from_documents(docs, show_progress=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Parsed {len(nodes)} nodes\")\n",
    "\n",
    "    return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b938b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_and_split_qa_pairs(pdf_files: list, temp_dataset_path=\"full_qa_dataset.json\", test_size=0.2):\n",
    "    print(\"Generating QA embedding pairs and splitting into train/test sets...\")\n",
    "    phi3_llm = HuggingFacePhi3LLM()\n",
    "\n",
    "    # Load all nodes from specified PDF files\n",
    "    all_nodes = []\n",
    "    for file in pdf_files:\n",
    "        all_nodes.extend(load_corpus([file]))\n",
    "\n",
    "    # Generate a single large QA embedding pair dataset\n",
    "    # We'll save it temporarily to disk as generate_qa_embedding_pairs works with output_path\n",
    "    temp_dataset = generate_qa_embedding_pairs(\n",
    "        llm=phi3_llm,\n",
    "        nodes=all_nodes,\n",
    "        output_path=temp_dataset_path\n",
    "    )\n",
    "\n",
    "    # Load the generated dataset into a Hugging Face Dataset object\n",
    "    full_dataset = EmbeddingQAFinetuneDataset.from_json(temp_dataset_path)\n",
    "\n",
    "    # Convert to Hugging Face datasets.Dataset for splitting\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": list(full_dataset.queries.keys()),\n",
    "        \"anchor\": list(full_dataset.queries.values()),\n",
    "        \"positive\": [full_dataset.corpus[full_dataset.relevant_docs[q_id][0]] for q_id in full_dataset.queries.keys()]\n",
    "    })\n",
    "    hf_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    train_test_split = hf_dataset.train_test_split(test_size=test_size)\n",
    "    train_hf_dataset = train_test_split[\"train\"]\n",
    "    test_hf_dataset = train_test_split[\"test\"]\n",
    "\n",
    "    # Prepare data for evaluator from the test set\n",
    "    test_queries = dict(zip(test_hf_dataset[\"id\"], test_hf_dataset[\"anchor\"]))\n",
    "    test_corpus = dict(zip(test_hf_dataset[\"id\"], test_hf_dataset[\"positive\"])) # For evaluation, each positive is its own corpus entry\n",
    "    test_relevant_docs = {}\n",
    "    for q_id in test_queries:\n",
    "        test_relevant_docs[q_id] = [q_id] # Query ID maps to its positive document ID\n",
    "\n",
    "    print(f\"Generated {len(train_hf_dataset)} training pairs and {len(test_hf_dataset)} test pairs.\")\n",
    "\n",
    "    return train_hf_dataset, test_queries, test_corpus, test_relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd148985",
   "metadata": {},
   "source": [
    "## Evaluator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3d5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(model_id=\"BAAI/bge-small-en-v1.5\"):\n",
    "    \"\"\"\n",
    "    Sets up the SentenceTransformer model.\n",
    "    \"\"\"\n",
    "    print(f\"Setting up model: {model_id}\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = SentenceTransformer(\n",
    "        model_id,\n",
    "        device=device,\n",
    "        model_kwargs={\"attn_implementation\": \"sdpa\"} if device == \"cuda\" else {},\n",
    "        model_card_data=SentenceTransformerModelCardData(\n",
    "            language=\"en\",\n",
    "            license=\"apache-2.0\",\n",
    "            model_name=\"BGE base Financial Matryoshka\",\n",
    "        ),\n",
    "    )\n",
    "    print(\"Model setup complete.\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2500ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_evaluator(queries, corpus, relevant_docs, matryoshka_dimensions=[256, 128, 64]):\n",
    "    \"\"\"\n",
    "    Sets up the sequential evaluator for different matryoshka dimensions.\n",
    "    \"\"\"\n",
    "    print(\"Setting up evaluator...\")\n",
    "    matryoshka_evaluators = []\n",
    "    for dim in matryoshka_dimensions:\n",
    "        ir_evaluator = InformationRetrievalEvaluator(\n",
    "            queries=queries,\n",
    "            corpus=corpus,\n",
    "            relevant_docs=relevant_docs,\n",
    "            name=f\"dim_{dim}\",\n",
    "            truncate_dim=dim,\n",
    "            score_functions={\"cosine\": cos_sim},\n",
    "        )\n",
    "        matryoshka_evaluators.append(ir_evaluator)\n",
    "    evaluator = SequentialEvaluator(matryoshka_evaluators)\n",
    "    print(\"Evaluator setup complete.\")\n",
    "    return evaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba16714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_trainer(model, train_dataset, evaluator, output_dir=\"bge-base-financial-matryoshka\", matryoshka_dimensions=[256, 128, 64]):\n",
    "    \"\"\"\n",
    "    Sets up the SentenceTransformerTrainer.\n",
    "    \"\"\"\n",
    "    print(\"Setting up trainer...\")\n",
    "    inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "    train_loss = MatryoshkaLoss(\n",
    "        model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    "    )\n",
    "\n",
    "    args = SentenceTransformerTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=4,\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=8,\n",
    "        per_device_eval_batch_size=16,\n",
    "        warmup_ratio=0.1,\n",
    "        learning_rate=2e-5,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        optim=\"adamw_torch_fused\",\n",
    "        tf32=False,\n",
    "        bf16=True,\n",
    "        batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=10,\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",\n",
    "    )\n",
    "\n",
    "    trainer = SentenceTransformerTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset.select_columns([\"positive\", \"anchor\"]),\n",
    "        loss=train_loss,\n",
    "        evaluator=evaluator,\n",
    "    )\n",
    "    print(\"Trainer setup complete.\")\n",
    "    return trainer, output_dir, args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b90896f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, evaluator, stage=\"Initial\"):\n",
    "    \"\"\"\n",
    "    Evaluates the model and prints the results.\n",
    "    \"\"\"\n",
    "    print(f\"Performing {stage} evaluation...\")\n",
    "    results = evaluator(model)\n",
    "    print(f\"\\n--- {stage} Evaluation Results ---\")\n",
    "    # Dynamically get matryoshka dimensions from evaluator if possible\n",
    "    matryoshka_dimensions = [e.truncate_dim for e in evaluator.evaluators if isinstance(e, InformationRetrievalEvaluator)]\n",
    "    if not matryoshka_dimensions: # Fallback if not directly obtainable\n",
    "        matryoshka_dimensions = [256, 128, 64]\n",
    "\n",
    "    for dim in matryoshka_dimensions:\n",
    "        key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "        if key in results:\n",
    "            print(f\"{key}: {results[key]:.4f}\")\n",
    "        else:\n",
    "            print(f\"Warning: {key} not found in results.\")\n",
    "    print(f\"--- End {stage} Evaluation Results ---\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e57bd",
   "metadata": {},
   "source": [
    "## Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa3ae944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Generate and split QA pairs\n",
    "    pdf_files = [\"mouch.pdf\", \"Production and Operations Management Systems.pdf\"]\n",
    "    train_dataset, test_queries, test_corpus, test_relevant_docs = generate_and_split_qa_pairs(pdf_files)\n",
    "\n",
    "    # Setup model\n",
    "    model = setup_model()\n",
    "\n",
    "    # Setup evaluator using the test data\n",
    "    evaluator = setup_evaluator(test_queries, test_corpus, test_relevant_docs)\n",
    "\n",
    "    # Initial evaluation\n",
    "    initial_results = evaluate_model(model, evaluator, stage=\"Initial\")\n",
    "\n",
    "    # Setup and train trainer\n",
    "    trainer, output_dir, args = setup_trainer(model, train_dataset, evaluator)\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    trainer.save_model() # Save the best model\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # Load the fine-tuned model for final evaluation\n",
    "    print(f\"Loading fine-tuned model from {output_dir} for final evaluation...\")\n",
    "    fine_tuned_model = SentenceTransformer(output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Final evaluation\n",
    "    final_results = evaluate_model(fine_tuned_model, evaluator, stage=\"Final\")\n",
    "\n",
    "    print(\"\\n--- Performance Difference (NDCG@10) ---\")\n",
    "    # Ensure we use the actual dimensions evaluated\n",
    "    matryoshka_dimensions = [e.truncate_dim for e in evaluator.evaluators if isinstance(e, InformationRetrievalEvaluator)]\n",
    "    if not matryoshka_dimensions:\n",
    "        matryoshka_dimensions = [256, 128, 64]\n",
    "\n",
    "    for dim in matryoshka_dimensions:\n",
    "        key = f\"dim_{dim}_cosine_ndcg@10\"\n",
    "        initial_score = initial_results.get(key, 0)\n",
    "        final_score = final_results.get(key, 0)\n",
    "        print(f\"Dimension {dim}: Initial {initial_score:.4f} -> Final {final_score:.4f} (Change: {final_score - initial_score:.4f})\")\n",
    "\n",
    "    # Clean up temporary dataset file\n",
    "    if os.path.exists(\"full_qa_dataset.json\"):\n",
    "        os.remove(\"full_qa_dataset.json\")\n",
    "        print(\"Cleaned up temporary file: full_qa_dataset.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cafde8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (1.8.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: psutil in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: filelock in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: networkx in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\e\\eil\\embeddings\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae1e6a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating QA embedding pairs and splitting into train/test sets...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Generate and split QA pairs\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     pdf_files \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmouch.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduction and Operations Management Systems.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m     train_dataset, test_queries, test_corpus, test_relevant_docs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_and_split_qa_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Setup model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m setup_model()\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mgenerate_and_split_qa_pairs\u001b[1;34m(pdf_files, temp_dataset_path, test_size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_and_split_qa_pairs\u001b[39m(pdf_files: \u001b[38;5;28mlist\u001b[39m, temp_dataset_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_qa_dataset.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating QA embedding pairs and splitting into train/test sets...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     phi3_llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFacePhi3LLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Load all nodes from specified PDF files\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     all_nodes \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mHuggingFacePhi3LLM.__init__\u001b[1;34m(self, model_name, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m'\u001b[39m, AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name))\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m, pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer))\n",
      "File \u001b[1;32md:\\E\\EIL\\embeddings\\.venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    601\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    602\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m )\n",
      "File \u001b[1;32md:\\E\\EIL\\embeddings\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32md:\\E\\EIL\\embeddings\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:4546\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 4546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4547\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4548\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4549\u001b[0m         )\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   4552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mValueError\u001b[0m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6588d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
